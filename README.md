## Integração Python LLaMA3 8B

Código para rodar com o modelo LLaMA3 da Meta

### Instruções:
- Siga a Instrução do [LLaMA3](https://github.com/meta-llama/llama3)
- Baixe os arquivos pelo [HugginFace](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B), (Será necessário um cadastro e liberação pelo Meta)
- Coloque todos os arquivos, na pasta `Meta-Llama-3.1-8B`
- Instale as [bibliotecas](requirements.txt) (Caso necessario utilize os .whl dentro da [pasta](bibliotecas))
- Execute o [IA_Hard-LLaMA.py](IA_Hard-LLaMA.py)

### Comentários:
Rodei com uma RTX 2080 limitando a 100 caracteres e funcionou normalmente (Sim, ocupou toda minha GPU) e as respostas demoraram em torno de 2min para serem geradas. 
